{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO8010: Homework 2\n",
    "\n",
    "Last week you learned how to program your first neural network starting from the very first principles of deep learning. If you managed to solve last week's assignment without any problems **congratulations!**, if that was not the case **don't worry**, here's a second assignment for you which you can use to get better at deep learning.\n",
    "\n",
    "In this homework we will see some slighly more complicated deep learning concepts: we will start by taking a look at some of PyTorch's functionalities that are necessary for training deep networks efficiently. We will then train our first neural networks for tackling different image classification tasks, learn to build custom datasets and explore how to train a CNN.  \n",
    "\n",
    "The strucutre of the notebook is identical to the one of the previous assignment. Similarly to last time you will have to handle in the notebook with your solutions to the exercises. When you will encounter the following instruction <span style=\"color:red; font-style: italic\"> Your code comes below </span> you will again have to write some code yourself, while when you will see the instruction: <span style=\"color:green; font-style: italic\"> Your discussion comes here </span> you will just have to discuss the results you obtained.\n",
    "\n",
    "Without further ado let's start by importing the libraries we will need throughout this assignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataloaders\n",
    "\n",
    "Today's first concept are PyTorch's dataloaders. As you have seen during the theoretical lectures, one of the main ingredients for successfully training deep learning models is data: **lots of data!**. \n",
    "\n",
    "As you can easily imagine, it is computationally not suitable to load datasets of millions of images into the memory of your machine, furthermore these images do also come in a form that does not make it possible to exploit the tensor operations we have seen in the previous assignment. \n",
    "\n",
    "To deal with these issues (and many more of them) we can use [dataloaders](https://pytorch.org/docs/stable/data.html), a data loading utility that allows us to deal with large datasets very efficiently. In what follows you are given your first example of dataloader which will use the popular [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "testset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explain what we just did. Thanks to the PyTorch [Torchvision](https://pytorch.org/vision/stable/index.html) package we just downloaded the CIFAR10 dataset on our machine. The dataset was stored in the `./data` folder and comes in two different forms thanks to the use of the `train` flag: a version that can be used as training set, and a version that can be used as testing set. These two datasets are abstracted through Torchvision `Dataset` sub-classes, we will see later in what this `Dataset` class consists exactly. Torchvision also allows us to define a set of image transformations which we have defined at the beginning of this cell: in this case we would like to convert our images to tensors, see the [doc](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ToTensor) for an exact description of this transformation. \n",
    "\n",
    "Now that we have defined which dataset we would like to use, and the form in which we would like to have our images we can create our very first dataloader that will load, transform and return us mini-batches of 4 images at the time that we can later on use for training. The advantage of dataloaders is that they can perform pre-processing of the data in parallel, e.g. while a batch is being processed in another thread of by your GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training anything however, let's take a look at the images we just downloaded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def show_images(img):\n",
    "    img = img \n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "show_images(torchvision.utils.make_grid(images))\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go: here's your first four images of the CIFAR10 dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some additional data transformations**\n",
    "\n",
    "The `transforms` module comes also in as very handy for performing other type of data transformations: here's an example which transforms the CIFAR10 images into gray scaled images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Grayscale(), transforms.ToTensor()])\n",
    "gray_scaled_trainset = datasets.CIFAR10(root=\"./data\", train=True, download=False, transform=transform)\n",
    "gray_scaled_trainloader = torch.utils.data.DataLoader(gray_scaled_trainset, batch_size=4, \n",
    "                                                      shuffle=True, num_workers=2)\n",
    "\n",
    "dataiter = iter(gray_scaled_trainloader)\n",
    "images, labels = dataiter.next()\n",
    "show_images(torchvision.utils.make_grid(images))\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the bug\n",
    "\n",
    "Al remembered from the theoretical lectures that one way to make neural networks more robust to overfitting can be based on data augmentation. Therefore he programmed this code snippet for performing random horizontal flips on his training set. However he encountered the following bug:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.RandomHorizontalFlip()])\n",
    "bugged_trainset = datasets.CIFAR10(root=\"./data\", train=True, download=False, transform=transform)\n",
    "bugged_trainloader = torch.utils.data.DataLoader(bugged_trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "dataiter = iter(bugged_trainloader)\n",
    "images, labels = dataiter.next()\n",
    "show_images(torchvision.utils.make_grid(images))\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix his mistake and discuss what he did wrong: put\n",
    "<span style=\"color:red; font-style: italic\">your code below</span> together <span style=\"color:green; font-style: italic\"> with your explanation</span>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However these images are not completely ready for a neural network, in fact Al forgot to perform a **very important** pre-processing step which could lead to vanishing gradient problems! \n",
    "\n",
    "What did Al not do? Fix his code snippet and candidate yourself as the next deep learning teaching assistant!\n",
    "\n",
    "<span style=\"color:red; font-style: italic\"> Your code comes below </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose() # write the sequence of appropriate transformations\n",
    "trainset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running operations on a GPU\n",
    "As you may know, one important aspect of deep learning is that large models can be trained efficiently on specialized hardwares such as Graphical Processing Units (GPUs) or Tensorial Processing Units (TPUs). Pytorch allows you to perform operations on GPUs very easily by simply transfering the concerned models and/or tensors to the GPU, see the following examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First you need to check that you have access to a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see `True`, everything is ready to run on the GPU and you can go to the next cell. Otherwise it means you do not have any GPU that is compatible with the torch version that is installed on your machine. We invite you to use [Google Colab](https://colab.research.google.com/) to do the rest of this homework. Do not forget to ask Colab for a GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the speed of tensor operations on GPU and CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# On CPU:\n",
    "A = torch.randn(1000, 100000)\n",
    "B = torch.randn(100000, 1)\n",
    "x = A @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# On GPU:\n",
    "device = 'cuda:0'\n",
    "for i in range(10):\n",
    "    # We directly create random tensors on the GPU\n",
    "    A = torch.randn((1000, 100000), device=device)\n",
    "    B = torch.randn((100000, 1), device=device)\n",
    "    x = A @ B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of directly creating a tensor on the GPU you may also transfer a model or a tensor on the GPU, for example we can transfer a simple MLP on the GPU and then back to the CPU as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MLP on CPU\n",
    "mlp = nn.Sequential(nn.Linear(2, 200), nn.ReLU(), \n",
    "                    nn.Linear(200, 200), nn.ReLU(), \n",
    "                    nn.Linear(200, 200), nn.ReLU(), \n",
    "                    nn.Linear(200, 200), nn.ReLU(), \n",
    "                    nn.Linear(200, 200), nn.ReLU(), \n",
    "                    nn.Linear(200, 1), nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Forward pass on CPU\n",
    "y_pred = mlp(torch.randn(100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Forward pass on GPU, be careful the input data must be on the GPU as well\n",
    "mlp = mlp.to('cuda:0')\n",
    "y_pred = mlp(torch.randn((100, 2), device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Forward pass back on CPU, be careful the input data must be on the CPU as well\n",
    "mlp = mlp.to('cpu')\n",
    "y_pred = mlp(torch.randn((100, 2), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may notice computations are more efficient on the GPU, however data transfer between GPU and CPU (and vice-versa) may be very slow, we therefore recommend you to reduce the transfer of data between GPU and CPU as much as possible. For example when you want to save your loss after each iteration, in order to avoid a memory leak you would prefer doing `.detach` (which will run on GPU without data transfer) instead of `.cpu()`, `.item()` or `.numpy()` (which would transfer data back to the CPU)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Classifying the CIFAR10 dataset with an MLP\n",
    "\n",
    "Now that you have all the necessary information about how to handle datasets, we are ready to properly train today's first deep learning model on the CIFAR10 dataset. Before we dive into it **do not underestimate** the importance of properly pre-processing the data before training neural networks. This step is as important as defining the neural architectures themeselves which however gets very often overlooked. Al Dente forgets to do it every year, and each year he complains about the bad grade he receives for the course.\n",
    "    \n",
    "In this exercise you will be provided with an already defined multi-layer perceptron that you can train to classify CIFAR10 images. The structure of the network is already defined, yet some crucial hyperparameters for training are missing. It is your job to fill them in and successfully train the network. As part of the exercise you are also required to monitor the evolution of training: this usually consists in keeping track of the accuracy that the model obtains on the training and testing sets, and in checking how the training and testing losses evolve while optimizing the network. Report these statistics with some plots. In addition, transfer the model and the data on GPU in order to fasten up the training.\n",
    "\n",
    "\n",
    "<span style=\"color:red; font-style: italic\"> Fill in the code below </span> and <span style=\"color:green; font-style: italic\"> describe </span> why you chose some parameters over others. Also discuss your results, are you satisifed with the final accuracy of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim =              # fill in with appropriate values\n",
    "hidden_dim = \n",
    "output_dim = \n",
    "learning_rate = \n",
    "num_epochs = \n",
    "\n",
    "class net(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(net, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.net = nn.Sequential(nn.Linear(input_dim, hidden_dim), nn.ReLU(),\n",
    "                                 nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),\n",
    "                                 nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),\n",
    "                                 nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x.view(x.size(0), self.input_dim))\n",
    "    \n",
    "device = 'cuda:0'\n",
    "model = net(input_dim, hidden_dim, output_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "transform = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) \n",
    "\n",
    "trainset = datasets.CIFAR10(root = \"./data\", train=True, download=True, transform=transform)\n",
    "testset = datasets.CIFAR10(root = \"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=True, num_workers=2)\n",
    "\n",
    "def train(num_epochs):\n",
    "    epochs_train_loss = []\n",
    "    epochs_test_loss = []\n",
    "    for i in range(num_epochs):\n",
    "        if i % 1 == 0:\n",
    "            with torch.no_grad():\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for inputs, targets in testloader:\n",
    "                    outputs = model(inputs.to(device))\n",
    "                    loss = criterion(outputs, targets.to(device))\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    total += targets.size(0)\n",
    "                    correct += predicted.eq(targets.to(device)).sum().item()\n",
    "\n",
    "            print('Accuracy of the model on the testing images: %d %%' % (100 * correct / total))\n",
    "        tmp_loss = []\n",
    "        for (x, y) in trainloader:\n",
    "            outputs = model(x.to(device))\n",
    "            loss = criterion(outputs, y.to(device))\n",
    "            tmp_loss.append(loss.detach())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return epochs_train_loss, epochs_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_train_loss, epochs_test_loss = train(num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the train and test loss here below:\n",
    "\n",
    "<span style=\"color:red; font-style: italic\"> Your code comes below </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Create a custom dataset!\n",
    "\n",
    "Sometimes you would like to train a model on your own dataset, which will very likely not be part of the Torchvision package. To overcome this you can create a custom dataset class which will handle the data for you. This can be done by inheriting from the `torch.utils.data.TensorDataset` class. \n",
    "\n",
    "In this exercise your goal is to program a custom dataset class which we will later use for training two different models. We will use the Kaggle Cats and Dogs Dataset which you can download from [here](https://www.microsoft.com/en-us/download/details.aspx?id=54765). \n",
    "\n",
    "When programming a custom dataset class you have to start by defining the constructor, which will get as input the location of your dataset, whether the images that will be returned will serve for training or testing, and some other potential attributes. For this exercise we will be using 20000 images for training, while 5000 ones for testing.  For the `__getitem__` function you may find the `PIL.Image.open` useful, do not forget to return the item class as well ($0$ or $1$).\n",
    "\n",
    "\n",
    "<span style=\"color:red; font-style: italic\"> Your code comes below</span>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import os\n",
    "\n",
    "class CatAndDogsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, train=True):\n",
    "        \"\"\"Initializes a dataset containing images and labels.\"\"\"\n",
    "        super().__init__()\n",
    "        # Your code\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the size of the dataset.\"\"\"\n",
    "        # Your code\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Returns the index-th data item of the dataset.\"\"\"\n",
    "        # Your code\n",
    "    \n",
    "transform = transforms.Compose([transforms.Resize((32, 32)), \n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a quick look at these samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(img):\n",
    "    img = img \n",
    "    npimg = img.numpy() * .5 + .5\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "my_dataset = CatAndDogsDataset('kagglecatsanddogs_3367a/PetImages/', transform=transform) # training directory\n",
    "my_loader = torch.utils.data.DataLoader(my_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "\n",
    "dataiter = iter(my_loader)\n",
    "images, labels = dataiter.next()\n",
    "show_images(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classifying the Cats and Dogs dataset with a CNN!\n",
    "\n",
    "As we have seen in class, classifying images with a multi-layer perceptron isn't really a good idea. Convolutional Neural Networks (CNN) are in fact a much better option for this task. It is now your job to create your custom CNN and train it on the Cats and Dogs Dataset.\n",
    "\n",
    "Similarly to what you have done when classifying the CIFAR10 dataset you are again required to report and discuss the performance of your model.\n",
    "\n",
    "<span style=\"color:red\"> Your code comes below </span> together <span style=\"color:green\"> with an explanation </span> about what has motivated you some of your design choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "\n",
    "Now that you are done with this final deep-learning assignment here are some final questions about the exercises you were required to solve:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">How much time did you spend on this homework?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Do you feel confortable with what it means to define a neural network and train it?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Do you think you now have enough preliminary knowledge for successfully starting to work on your course final project?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">If you had to go through the two homeworks again, is there something you would have liked to explore more or explained more into detail?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
